
### --------- Getting Started ---------

pacman::p_load(shiny, shinythemes, tidyverse, rpart, 
               rpart.plot, shinyWidgets, plotly, caret, tibble)
set.seed(123)

# loading data
hotel_data <- read.csv('data/hotel.csv')
hotel_data <- hotel_data %>% select(-Country,-Agent,-Company)

# split train and test
data_size=nrow(hotel_data)
index <- sample(1:data_size, size = trunc(.8 * data_size))
train_df <- hotel_data %>%
  filter(row_number() %in% index)

test_df <- hotel_data %>%
  filter(!(row_number() %in% index))

# for decision tree
var_list <- list(
  "No. of Non-Canceled Previous Bookings"="PreviousBookingsNotCanceled", 
  "No. of Previous Cancallations"="PreviousCancellations",  
  "No. of Special Requests"="TotalOfSpecialRequests",
  "No. of Changes Made"="BookingChanges",  
  "Hotel Type"="hotelType",    
  "Customer Type"="CustomerType", 
  "Deposit Type"="DepositType",   
  "Lead Time"="LeadTime",                   
  "Market Segment"="MarketSegment",   
  "Distribution Channel"="DistributionChannel", 
  "Reserved Room Type"="ReservedRoomType", 
  "Assigned Room Type"="AssignedRoomType",
  "Avg. Daily Rate"="ADR",
  "No. of Adults"="Adults",
  "No. of Babies"="Babies",
  "No. of Children"="Children",
  "No. of Days in Waiting List"="DaysInWaitingList",          
  "Is Repeated Guest?"="IsRepeatedGuest",             
  "Required CarParking Spaces?"="RequiredCarParkingSpaces"
)
var_list_default <- var_list[1:9]

# for LR model
lr_var_list <- list(
  "No. of Non-Canceled Previous Bookings"="PreviousBookingsNotCanceled", 
  "No. of Previous Cancallations"="PreviousCancellations",  
  "No. of Special Requests"="TotalOfSpecialRequests",
  "No. of Changes Made"="BookingChanges",  
  "Hotel Type"="hotelType",    
  "Customer Type"="CustomerType", 
  "Deposit Type"="DepositType",   
  "Lead Time"="LeadTime",                   
  "Market Segment"="MarketSegment",   
  "Distribution Channel"="DistributionChannel", 
  "Reserved Room Type"="ReservedRoomType", 
  "Assigned Room Type"="AssignedRoomType",
  "Avg. Daily Rate"="ADR",
  "No. of Adults"="Adults",
  "No. of Babies"="Babies",
  "No. of Children"="Children",
  "No. of Days in Waiting List"="DaysInWaitingList",          
  "Is Repeated Guest?"="IsRepeatedGuest",             
  "Required CarParking Spaces?"="RequiredCarParkingSpaces"
)
lr_var_list_default <- lr_var_list[1:9]



### --------- functions --------
makeTree = function(model_vars, min_split, min_bucket, max_depth) {
  # Takes a list of model variables (strings), a minimum split parameter
  # (int), a minimum bucket size parameter (int), and a maximum tree depth
  # parameter (int) as inputs and then returns an rpart classification tree
  # created with those parameters using Gini-indexes without any pruning.
  
  train_dat = train_df
  # create an rpart compatible formula for the model from the chosen vars
  f = paste("IsCanceled ~ ", paste(model_vars, collapse = " + "))
  # rpart is performs the split calculations and returns the tree
  tree = rpart(
    as.formula(f),
    method = "class",  # sets it up as a classification problem
    data = train_dat,
    parms = list(prior = c(.5,.5), split = "information"),  # ensures rpart uses gini indexes
    minsplit = min_split,
    minbucket = min_bucket,
    maxdepth = max_depth,
    cp = 0  # complexity parameter, at zero prevents pruning on branches
  )
  
  return(tree)
}

useTree = function(tree,df) {
  # Takes a tree generated by rpart and a filename (string) as input and
  # then predicts the labels of the data in that file using the tree. It
  # returns a dataframe with two bool (0,1) columns: prediction and truth.
  
  data = df
  prediction = predict(tree, data, type = "class")
  results = as.data.frame(prediction)
  results$truth = data$IsCanceled
  
  return(results)
}

# Evaluation
calcScores = function(results) {
  
  results = table(results)
  
  # Calculate accuracy
  accuracy <- round((results[1,1]+results[2,2])/sum(results),3)*100
  
  # Calculate precision
  precision <- round(results[2,2]/sum(results[2,]),3)*100
  
  # Calculate recall
  recall <- round(results[2,2]/sum(results[,2]),3)*100
  
  # the collapse argument removes the spacing which would otherwise be there
  return(list(
    paste(c("Overall Accuracy: ",   accuracy, "%"), collapse = ""),
    paste(c("Precision: ", precision, "%"), collapse = ""),
    paste(c("Recall: ", recall, "%"), collapse = "")
  ))
}

# Confusion Matrix
resultsTable = function(results) {

  data = table(results)
  Outcomes = c("Predicted Not Cancelled", "Predicted Cancelled", "Total")
  # reconstruct the columns of R's table(...) CLI display
  c1 = c(data[, 1], sum(data[, 1]))  #TN, FN, Sum(TN, FN)
  c2 = c(data[, 2], sum(data[, 2]))  #FP, TP, Sum(TP, FP)
  c3 = c(sum(data[, 1]), sum(data[2, ]), sum(data))
  
  # turn these columns back into a dataframe but with proper headers
  output = data.frame(Outcomes)
  output$"Actually Not Cancelled" = c1
  output$"Actually Cancelled" = c2
  output$"Total" = c3
  
  return(output)
}

corrplot_num = function(df){
  df <- na.omit(df)
  numeric_var <- names(df)[sapply(df[names(df)], is.numeric)]
  num_df <- df[, numeric_var[2:length(numeric_var)]]
  
  # calculate the correlation matrix
  corr_mat <- cor(num_df)
  
  # Create correlation heatmap with plotly
  p <- plot_ly(z = corr_mat, type = "heatmap", colorscale = "RdBu", reversescale = TRUE,
          x = colnames(corr_mat), y = colnames(corr_mat)) %>%
    layout(title = "Correlation Heatmap of Numerical Variables",
           xaxis = list(tickangle = 30),
           yaxis = list(showticklabels = FALSE))
  
  return(p)
}

makeLR = function(model_vars){
  data = train_df
  
  data[data==""]<-NA
  data[data=="NULL"]<-NA
  
  data$hotelType=as.factor(data$hotelType)  
  data$ArrivalDateMonth=as.factor(data$ArrivalDateMonth)  
  data$Meal=as.factor(data$Meal)  
  data$MarketSegment=as.factor(data$MarketSegment)  
  data$DistributionChannel=as.factor(data$DistributionChannel)  
  data$ReservedRoomType=as.factor(data$ReservedRoomType)  
  data$AssignedRoomType=as.factor(data$AssignedRoomType)  
  data$DepositType=as.factor(data$DepositType)   
  data$CustomerType=as.factor(data$CustomerType)
  
  # create an rpart compatible formula for the model from the chosen vars
  f = paste("IsCanceled ~ ", paste(model_vars, collapse = " + "))
  
  lr_model=glm(as.formula(f),data=data,family=binomial(link="logit"))
  
  return(lr_model)
}

useLR = function(model, df) {
  # Takes a tree generated by rpart and a filename (string) as input and
  # then predicts the labels of the data in that file using the tree. It
  # returns a dataframe with two bool (0,1) columns: prediction and truth.
  
  data = df
  prediction = predict(model, data, type = "response")
  prediction = as.factor(ifelse(prediction>0.5,1,0))
  results = as.data.frame(prediction)
  results$truth = data$IsCanceled

  return(results)
}

var_imp_plot = function(varImp){
  
  # calculate variable importance
  varImp <- varImp %>% 
    arrange(desc(Overall)) %>%
    rownames_to_column(var = "Variable") %>%
    slice_head(n = 10)  %>%
    mutate(Variable = str_trim(Variable))
  
  print(varImp)
  
  # create a bar chart of the variable importance measures
  p <- plot_ly(data = varImp, y = ~Variable, x = ~Overall, type = "bar", color = "#eab676") %>%
    layout(title = "Variable Importance Measures",
           yaxis = list(
             title = "Predictor Variable",
             categoryorder = "total ascending"),
           xaxis = list(title = "Importance")
    )
  return(p)
}

# ------- Shiny UI --------

ui <- navbarPage(
  title = "Hotel Data Analytical Dashboard",
  fluid = TRUE,
  theme='simplex',
  id = "navbarID",
  tabPanel("User Guide",
           icon = icon('person-chalkboard'),
           h1("Welcome to our App!"),
           mainPanel(
             tags$a(href="https://github.com/mtlmh34/Visual-Analytics-Grp-Project/blob/main/README.md", "Click Here for user guide!")
           )
  ),
  
  ######### Page 1
  navbarMenu("Know Your Business", 
             icon = icon('briefcase'),
             tabPanel("Rates",
             ),
             tabPanel("Cancellations",
             ),
             tabPanel("Revenue",
             )
  ),
  
  ######### Page 2
  navbarMenu(
    "Know Your Customers",
    icon = icon('address-card'),
    tabPanel(
      "Demographics",
    ),
    tabPanel(
      "Preference",
    )
  ),
  
  ######### Page 3
  navbarMenu(
    "Predictive Analysis",
    icon = icon("chart-line"),
    tabPanel(
      "Decision Tree: Cancellation Prediction",
      sidebarLayout(
        sidebarPanel(
          h3("The Controls"),
          br(),
          
          actionBttn(
            inputId = "createTreeModel",
            label = "Create Tree",
            class = "primary"  # makes it blue!
          ),
          actionBttn(
            inputId = "testTreeModel",
            label = "Test Tree",
            color = "danger"  # makes it red!
          ),
          
          br(),
          
          h3("Model Features"),
          helpText(
            'Here are the choices of the predictors to choose:'
          ),
          pickerInput(
            inputId = "model_vars",
            label = NULL,  # label given in outer code
            choices = var_list,
            selected = var_list_default,
            options = list(`actions-box` = TRUE),
            multiple = TRUE
          ),
          
          br(),
          "Here are some hyperparameters for tuning the DT: ",
          
          h4("Minimum Split"),
          helpText(
            "Control the minimum size allowed for the node to split further"
          ),
          sliderInput(
            inputId = "min_split",
            label = NULL,  # label given in outer code
            min = 500,       # two is the smallest that could be split
            max = 10000,      # chosen to not make the models too wild
            value = 1000,      # defaults to not having an artifical minimum,
            step=500
          ),
          
          br(),
          
          h4("Minimum Bucket Size"),
          helpText(
            "Control the minimum size allowed in the terminal node"
          ),
          sliderInput(
            inputId = "min_bucket",
            label = NULL,  # label given in outer code
            min = 100,       # can't have buckets of size zero
            max = 3000,      # rpart default is minbucket = 3*minsplit
            value = 500,     # defaults to not having an artifical minimum
            step = 100
          ),
          br(),
          h4("Maximum Tree Depth"),
          helpText(
            "Control the maximum depth that the decision tree can reach"
          ),
          sliderInput(
            inputId = "max_depth",
            label = NULL,  # label given in outer code
            min = 2,       # a min of 2 allows for at least one split
            max = 15,      # rpart can't do 31+ depth on 32-bit machines
            value = 5      # chosen to not make the default too wild
          )
        ), #SidebarPanel
        mainPanel(
          fluidRow(
            label = NULL,
            column(6,
                   h3("Training Results"),
                   br(),
                   # training accuracy, precision, recall
                   tagAppendAttributes(
                     textOutput("tree_training_scores"),
                     # allow linebreaks between scores, larger font here
                     style = "white-space: pre-wrap; font-size: 17px;"
                   ), 
                   # training results table matches layout from presentation
                   tableOutput("tree_training_table")
            ), # column 1
            column(6,
                   h3("Test Results"),
                   br(),
                   # test accuracy, precision, recall
                   tagAppendAttributes(
                     textOutput("tree_test_scores"),
                     # allow linebreaks between scores, larger font here
                     style = "white-space: pre-wrap; font-size: 17px;"
                   ),
                   # training results table matches layout from presentation
                   tableOutput("tree_test_table")
            ) # column 2
          ), # fluidRow
          fluidRow(
            column(8,
                   h3("Decision Tree"),
                   helpText(
                     "Class 0: Predicted not Canceled; Class 1: Predicted Canceled"
                   ),
                   plotOutput(outputId = "tree_plot")
            ), #column 1
            column(4,
                   h3("Classification"),
                   "- The tree graph on the left dicpicts the suggested method by a trained decision tree model,
                                   which classfies whether a customer is likely to cancelled the order. "
                   ,
                   br(),br(),
                   "- The accuracy of the model can be referred by the training and testing accuracy on the top.",
                   br(),br(),
                   "- Operation team can utilise this model as a guide and pay extra attentions to the customer who are likely to churn."
            ) # column 2
          ) #FluidRow
        )#mainPanel
      )#SidebarLayout
    ), #tabPanel 1
   tabPanel(
     "Logistic Regression: Cancellation Prediction",
     sidebarLayout(
       sidebarPanel(
         h3("The Controls"),
         br(),
         
         actionBttn(
           inputId = "createLRModel",
           label = "Create Model",
           class = "primary"  # makes it blue!
         ),
         actionBttn(
           inputId = "testLRModel",
           label = "Test Model",
           color = "danger"  # makes it red!
         ),
         
         br(),
         
         h3("Model Features"),
         helpText(
           'Here are the choices of the predictors to choose:'
         ),
         pickerInput(
           inputId = "lr_model_vars",
           label = NULL,  # label given in outer code
           choices = lr_var_list,
           selected = lr_var_list_default,
           options = list(`actions-box` = TRUE),
           multiple = TRUE
         ), 
         
         br(),
         
         h3("Test For Multi-Collinearity"),
         helpText("Below shows the correlations between each of the numerical variables.
                  Highly correlated pairs need to be excluded from the logistic regression model."),
         plotlyOutput(outputId = "num_corr_plot"),
       ),#sidebarPanel
       mainPanel(
         fluidRow(
           label = NULL,
           column(6,
                  h3("Training Results"),
                  br(),
                  # training accuracy, precision, recall
                  tagAppendAttributes(
                    textOutput("lr_training_scores"),
                    # allow linebreaks between scores, larger font here
                    style = "white-space: pre-wrap; font-size: 17px;"
                  ), 
                  # training results table matches layout from presentation
                  tableOutput("lr_training_table")
           ), # column 1
           column(6,
                  h3("Test Results"),
                  br(),
                  # test accuracy, precision, recall
                  tagAppendAttributes(
                    textOutput("lr_test_scores"),
                    # allow linebreaks between scores, larger font here
                    style = "white-space: pre-wrap; font-size: 17px;"
                  ),
                  # training results table matches layout from presentation
                  tableOutput("lr_test_table")
           ) # column 2
         ), # fluidRow
         fluidRow(
           h3("Importance of Variables"),
           plotlyOutput("lr_var_importance_bar")
         )
       )#MainPanel
     )#SidebarLayout
   )#TabPanel
  )#navbarMenu
)#NavbarPage



# ------- server --------
server <- function(input, output) {
  #------ INPUT EVENT REACTIONS -----
  #------ Decision Tree --------
  # reconstruct the tree every time createModel is pressed
  tree = eventReactive(
    eventExpr = input$createTreeModel,
    valueExpr = makeTree(
      model_vars = input$model_vars,
      input$min_split, input$min_bucket, input$max_depth
    )
  )
  
  # regenerate training results every time createModel is pressed
  tree_training_results = eventReactive(
    eventExpr = input$createTreeModel,
    valueExpr = useTree(tree(), train_df)
  )
  
  # regenerate test results every time createModel is pressed
  tree_test_results = eventReactive(
    eventExpr = input$testTreeModel,
    valueExpr = useTree(tree(), test_df)
  )
  
  #------ Logistic Regresion --------
  lr = eventReactive(
    eventExpr = input$createLRModel,
    valueExpr = makeLR(input$lr_model_vars)
  )
  
  # regenerate training results every time createModel is pressed
  lr_training_results = eventReactive(
    eventExpr = input$createLRModel,
    valueExpr = useLR(lr(), train_df)
  )
  
  # regenerate test results every time createModel is pressed
  lr_test_results = eventReactive(
    eventExpr = input$testLRModel,
    valueExpr = useLR(lr(), test_df)
  )
  
  lr_var_importance = eventReactive(
    eventExpr = input$createLRModel,
    valueExpr = varImp(lr(), scale = FALSE)
  )
  
  #------ OUTPUT DISPLAY PREP ------
  # assessment scores are each collapsed to display on a new line
  output$tree_training_scores = renderText(
    paste(calcScores(tree_training_results()), collapse = "\n")
  )
  output$tree_test_scores = renderText(
    paste(calcScores(tree_test_results()), collapse = "\n")
  )
  
  # tables of outcome breakdows are static widgets
  output$tree_training_table = renderTable(
    resultsTable(tree_training_results()),
    align = "lccc",  # left-align first column, centre rest
    striped = TRUE
  )
  output$tree_test_table = renderTable(
    resultsTable(tree_test_results()),
    align = "lccc",  # left-align first column, centre rest
    striped = TRUE
  )
  # frame for a plot of the decision tree
  output$tree_plot = renderPlot(
    prp(
      tree(), roundint = FALSE,
      # neaten up the nodes and edges, remove detailed labels
      extra = 0, branch = 0, varlen = 0,
      # colours spam terminals in red, non-spam terminals in blue
      box.col = c("cornflowerblue", "tomato")[tree()$frame$yval]
    )
  )
  #correlation heatmap
  output$num_corr_plot = renderPlotly(
    corrplot_num(hotel_data)
  )
  
  output$lr_training_scores = renderText(
    paste(calcScores(lr_training_results()), collapse = "\n")
  )
  output$lr_test_scores = renderText(
    paste(calcScores(lr_test_results()), collapse = "\n")
  )
  
  # tables of outcome breakdows are static widgets
  output$lr_training_table = renderTable(
    resultsTable(lr_training_results()),
    align = "lccc",  # left-align first column, centre rest
    striped = TRUE
  )
  output$lr_test_table = renderTable(
    resultsTable(lr_test_results()),
    align = "lccc",  # left-align first column, centre rest
    striped = TRUE
  )
  
  output$lr_var_importance_bar = renderPlotly(
    var_imp_plot(lr_var_importance())
  )
}



# ------- Run the application -------
shinyApp(ui = ui, server = server)
